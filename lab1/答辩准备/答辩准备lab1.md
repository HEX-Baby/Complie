#  一、程序结构

## 文件结构总览
```
main.cpp
  │
  ├─ FE::Parser (parser.h)
  │     │
  │     ├─ Scanner (scanner.h)
  │     │     │
  │     │     └─ lexer.l (Flex 规则)
  │     │           │
  │     │           └─ yacc.h (Token 定义)
  │     │
  │     └─ YaccParser (yacc.y)
  │
  └─ FE::Token (token.h)
```
## 程序结构图

```
┌─────────────────────────────────────────────────────────────┐
│                      编译器主程序 (main.cpp)                 │
│                                                             │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  命令行参数解析                                        │  │
│  │  - 输入文件路径                                        │  │
│  │  - 输出文件路径                                        │  │
│  │  - 执行阶段 (-lexer, -parser, 等)                    │   │
│  └──────────────────┬───────────────────────────────────┘   │
│                     │                                       │
│                     ▼                                       │
│  ┌──────────────────────────────────────────────────────┐   │
│  │          FE::Parser (parser.h/cpp)                    │  │
│  │          词法/语法分析器控制器                         │   │
│  └──────────┬───────────────────┬───────────────────────┘   │
│             │                   │                            │
│             │ parseTokens()     │ parseAST()                 │
│             │                   │                            │
└─────────────┼───────────────────┼────────────────────────────┘
              │                   │
              │                   │
┌─────────────▼───────────────────▼─────────────────────────────┐
│                 Frontend 前端模块                              │
│                                                              │
│  ┌────────────────────────────────────────────────────────┐  │
│  │           词法分析器 (Lexer)                            │  │
│  │                                                        │  │
│  │  ┌──────────────────────────────────────────────────┐  │  │
│  │  │  Scanner (scanner.h + lexer.l)                   │  │  │
│  │  │  - 基于 Flex 生成                                 │  │  │
│  │  │  - 读取源代码字符流                                │  │  │
│  │  │  - 根据正则表达式匹配                              │  │  │
│  │  └────────────────┬─────────────────────────────────┘ │  │
│  │                   │                                    │  │
│  │                   │ 输出 Token                         │  │
│  │                   ▼                                    │  │
│  │  ┌──────────────────────────────────────────────────┐ │  │
│  │  │  Token 类型 (yacc.h)                             │  │  │
│  │  │  - INT_CONST    (整数常量)                       │  │  │
│  │  │  - FLOAT_CONST  (浮点常量)                       │  │  │
│  │  │  - IDENT        (标识符)                         │  │  │
│  │  │  - 关键字 (if, else, for, while...)              │  │  │
│  │  │  - 运算符 (+, -, *, /, ==, !=...)                │  │  │
│  │  │  - 分隔符 (;, ,, (, ), {, }...)                  │  │  │
│  │  └────────────────────────────────────────────────── ┘ │  │
│  └────────────────────────────────────────────────────────┘  │
│                                                              │
│  ┌────────────────────────────────────────────────────────┐  │
│  │           Token 转换层 (parser.cpp)                     │  │
│  │                                                        │  │
│  │  parseTokens_impl():                                   │  │
│  │  - 调用 Scanner::nextToken()                           │  │
│  │  - 提取 Token 的值和属性                                │  │
│  │  - 转换为统一的 FE::Token 结构                          │  │
│  └────────────────────────────────────────────────────────┘  │
│                                                              │
│  ┌────────────────────────────────────────────────────────┐  │
│  │           Token 定义 (token.h)                          │  │
│  │                                                        │  │
│  │  struct Token {                                        │  │
│  │    string token_name;      // Token 名称               │  │
│  │    string lexeme;          // 原始文本                  │  │
│  │    int line_number;        // 行号                     │  │
│  │    int column_number;      // 列号                     │  │
│  │    TokenType type;         // 类型                     │  │
│  │    union { int, float, long long };  // 值             │  │
│  │  }                                                     │  │
│  └────────────────────────────────────────────────────────┘  │
└───────────────────────────────────────────────────────────────┘
```

##  数据流

```
测试源代码文件 (.sy)
    │
    ▼
┌────────────────┐
│ 文件输入流      │
│ (ifstream)     │
└───────┬────────┘
        │
        ▼
┌────────────────────────────┐
│  Scanner (Flex 生成)        │
│  - 逐字符读取                │
│  - 正则表达式匹配            │
│  - 状态机转换                │
└───────┬────────────────────┘
        │
        ▼
┌────────────────────────────┐
│  YaccParser::symbol_type   │
│  (Bison Token 格式)        │
│  - kind: Token 类型         │
│  - value: Token 值          │
│  - location: 位置信息       │
└───────┬────────────────────┘
        │
        ▼
┌────────────────────────────┐
│  Parser::parseTokens_impl  │
│  - 转换 Token 格式          │
│  - 提取值和属性              │
└───────┬────────────────────┘
        │
        ▼
┌────────────────────────────┐
│  FE::Token (统一格式)       │
│  - token_name               │
│  - lexeme                   │
│  - type, value              │
│  - line, column             │
└───────┬────────────────────┘
        │
        ▼
┌────────────────────────────┐
│  vector<Token>             │
│  (Token 序列)               │
└───────┬────────────────────┘
        │
        ▼
┌────────────────────────────┐
│  main.cpp 输出格式化        │
│  - 打印为表格形式            │
│  - Token | Lexeme | Property│
└───────┬────────────────────┘
        │
        ▼
输出文件 (.out) 或 标准输出
```



#  二、常见问题：


### 什么是词法分析？它在编译器中的作用是什么？



词法分析是编译器的第一个阶段，主要作用是将源代码的字符流转换为Token序列，
自动处理底层细节（空白、注释、换行等）为语法分析提供结构化的输入



### Token和Lexeme的区别是什么？



 lexme是源代码中的原始字符序列 ，Token是Lexeme的抽象分类

例如：
```
Lexeme: "if"    → Token: IF 
Lexeme: "abc"   → Token: IDENT 
Lexeme: "3.14"  → Token: FLOAT_CONST 
```

---

### 项目中如何识别浮点数？


将浮点数拆分成三个规则：


```lex
1. \.[0-9]+                    // .5, .123
2. [0-9]+\.[0-9]+              // 3.14, 123.456
3. [0-9]+\.                    // 5., 123.
```


原来的规则 `([0-9]*\.[0-9]+|[0-9]+\.[0-9]*)` 存在可以匹配空串的问题，
导致 `.5` 匹配时出现歧义，Flex可能不确定如何处理前面的"空"， `5.` 可能被拆分为整数 `5` + 未知符号 `.`
最长匹配原则可能因此失效，于是简单粗暴的办法就是拆三个



### 项目中遇到了什么问题？如何解决的？

Property列为空，但是词法分析器正确识别了字符串，但 parser（parseTokens_impl()） 中缺少对 S_FLOAT_CONST的处理
浮点数Token进入 `default` 分支，type被设为 `T_NONE`输出时检查 `type == T_FLOAT`，不满足，所以不输出值


### 是如何工作的？


使用`convertToFloatDec()` 函数



整数部分逐位累加，（左移），小数部分除以位权，科学计数法使用 pow函数，结果与 `FLT_MAX` 比较

如下：

```
输入: "123.456e-2"

1: 解析整数部分
    123 = 1×10² + 2×10¹ + 3×10⁰ = 123

2: 解析小数部分
    .456 = 4×10⁻¹ + 5×10⁻² + 6×10⁻³ = 0.456

3: 合并
    value = 123 + 0.456 = 123.456

4: 应用指数
    exponent = -2
    value = 123.456 × 10⁻² = 1.23456

5: 检查溢出
    if (value > FLT_MAX) throw overflow;
```



### 什么是DFA和NFA？它们有什么区别？


**NFA (非确定有限自动机)**
对于一个状态和输入字符，可能有**多个**下一状态，可以有 ε-转换（不消耗输入的转换），易于构造，但执行时需要回溯

**DFA (确定有限自动机)**
对于一个状态和输入字符，**有且仅有一个**下一状态，没有 ε-转换，执行高效，但状态数可能指数增长
Flex使用DFA的原因：保证线性时间复杂度



### Flex如何将正则表达式转换为词法分析器？


正则表达式
    ↓ Thompson构造法
NFA (非确定有限自动机)
    ↓ 子集构造法
DFA (确定有限自动机)
    ↓ Hopcroft算法
最小化DFA
    ↓ 代码生成
C/C++词法分析器代码



### Q9: 为什么词法分析的时间复杂度是？

答：O（n）

DFA的确定性保证不需要尝试多条路径,无需回溯,每个字符只需查表一次：O(1),处理n个字符：O(n)





###  词法分析器如何处理错误？



1. **非法字符**：无法匹配任何规则的字符
2. **数值溢出**：超出数据类型范围
3. **格式错误**：不完整或错误的字面量

**处理策略（Panic Mode）：**
```cpp
try {
    float val = convertToFloatDec(yytext);
    return make_FLOAT_CONST(val, loc);
} catch (const std::exception& e) {
    // 1. 报告错误
    _parser.reportError(loc, 
        "Invalid float: " + e.what());
    
    // 2. 返回错误Token，继续分析
    return make_ERR_TOKEN(yytext, loc);
}
```


###  如何处理浮点数溢出？


```cpp
// 在转换完成后检查
if (value > std::numeric_limits<float>::max() || 
    value < -std::numeric_limits<float>::max()) {
    throw std::out_of_range("Float overflow");
}
```



### 词法分析器还可以如何优化？


实际上限制性能的大多不是算法问题，而是IO问题
1. **I/O优化**
   ```cpp
   // Flex使用双缓冲
   - 一个缓冲区读取文件
   - 另一个缓冲区处理字符
   - 减少系统调用次数
   ```

2. **状态表压缩**
   ```
   - 使用稀疏矩阵表示
   - 减少内存占用
   - 提高缓存命中率
   ```

3. **内存池**
   ```cpp
   // Token对象重用
   - 预分配Token数组
   - 减少new/delete次数
   ```

4. **避免不必要的拷贝**
   ```cpp
   // 使用引用和move语义
   return make_FLOAT_CONST(std::move(value), loc);
   ```




### 如何扩展词法分析器以支持新的Token类型？

在 yacc.y 中声明 Token，随后在 lexer.l 中添加规则，放入parser.cpp 中处理，
最后在 token.h 中添加一个枚举类型的变量类型


### 支持多行注释嵌套如何实现？

当 Lex 识别到开始注释符号 /* 时进入 COMMENT 状态，并初始化嵌套深度 depth 为 1，表示当前有一个注释块。
当在 COMMENT 状态下再次遇到开始注释符号 /* 时，这表示嵌套了一层注释，因此深度增加 1。

在 COMMENT 状态下遇到结束注释符号 */ 时，深度减少 1，如果深度减为 0，表示所有嵌套的注释都已结束，返回到 INITIAL 状态。

在 COMMENT 状态下，遇到任何其他字符时将它们忽略，因为它们是注释内容的一部分。
在 COMMENT 状态下遇到换行符时进行记录。这通常用于更新行号计数，以便后续的错误报告或调试信息能够准确反映源代码的行号


如下代码：
```lex
%x COMMENT

%%
"/*"            { BEGIN(COMMENT); depth = 1; }
<COMMENT>"/*"   { depth++; }
<COMMENT>"*/"   { if (--depth == 0) BEGIN(INITIAL); }
<COMMENT>.      { /* ignore */ }
<COMMENT>\n     { loc.lines(1); }
```


### 请解释最长匹配原则和先定义优先原则。


**最长匹配原则**

 总是匹配尽可能长的字符序列


一个字符串if123
可以匹配规则1`"if"` （长度2）也可以匹配规则2`"if123"`（长度5）
选择更长的规则2

**先定义优先原则**

相同长度时，选择先定义的规则
两个规则都匹配，长度相同选择先定义的规则（默认高优先）



# 三、终结符号：

定义于yacc.y，这些定义好的终结符会在lex中进行映射

// ---------- 关键字 ----------     
%}

"if"                { RETT(IF, loc) }
"else"              { RETT(ELSE, loc) }
"for"               { RETT(FOR, loc) }
"while"             { RETT(WHILE, loc) }
"continue"          { RETT(CONTINUE, loc) }
"break"             { RETT(BREAK, loc) }
"switch"            { RETT(SWITCH, loc) }
"case"              { RETT(CASE, loc) }
"goto"              { RETT(GOTO, loc) }
"do"                { RETT(DO, loc) }
"return"            { RETT(RETURN, loc) }
"const"             { RETT(CONST, loc) }

"int"               { RETT(INT, loc)}
"float"             { RETT(FLOAT, loc)}
"void"              { RETT(VOID, loc)}
"double"            { RETT(DOUBLE, loc)}

%{
// ---------- 符号 ---------- 
%}

";"                 { RETT(SEMICOLON, loc) }
","                 { RETT(COMMA, loc) }
"("                 { RETT(LPAREN, loc) }
")"                 { RETT(RPAREN, loc) }
"["                 { RETT(LBRACKET, loc) }
"]"                 { RETT(RBRACKET, loc) }
"{"                 { RETT(LBRACE, loc) }
"}"                 { RETT(RBRACE, loc) }

%{
// ====================== 算术运算符 ======================
%}
"+"                 { RETT(PLUS, loc) }
"-"                 { RETT(MINUS, loc) }
"*"                 { RETT(STAR, loc) }
"/"                 { RETT(SLASH, loc) }
"%"                 { RETT(MOD, loc) }  


%{
// ====================== 关系运算符 ======================
%}
"!="                { RETT(NEQ, loc) }
"=="                { RETT(EQ, loc) }
"<="                { RETT(LE, loc) }
"<"                 { RETT(LT, loc) }
">="                { RETT(GE, loc) }
">"                 { RETT(GT, loc) }

"="                 { RETT(ASSIGN, loc) }

%{
// ====================== 逻辑运算符 ======================
%}
"&&"      { RETT(LAND, loc) }        // 逻辑与
"||"      { RETT(LOR, loc) }         // 逻辑或
"!"       { RETT(LNOT, loc) }        // 逻辑非

%{
// ====================== 位运算符 ======================
%}
"&"       { RETT(BITAND, loc) }      // 按位与
"|"       { RETT(BITOR, loc) }       // 按位或
"^"       { RETT(BITXOR, loc) }      // 按位异或
"~"       { RETT(BITNOT, loc) }      // 按位取反


我们可以添加一些我们需要的终结符：
例如：
"strcpy"               { RETT(STRCPY, loc) }
"cat"             { RETT(CAT, loc) }
首先在在 yacc.y 中声明，随后在 lexer.l 中定义识别规则，在parser中处理

# 四、课外拓展：


### 整体架构

```
┌─────────────────────────────────────────────────────────┐
│                    Lex 工具实现                          │
└───────┬───────────────────────────────┬─────────────────┘
        │                               │
        ▼                               ▼
┌──────────────────┐          ┌──────────────────┐
│  编译时（离线）    │          │  运行时（在线）    │
│                  │          │                  │
│  .l 文件         │          │  源代码           │
│     ↓            │          │     ↓            │
│  正则表达式      │          │  词法分析器       │
│     ↓            │          │     ↓            │
│  Thompson构造    │          │  Token流          │
│     ↓            │          │                  │
│  NFA             │          └──────────────────┘
│     ↓            │
│  子集构造        │
│     ↓            │
│  DFA             │
│     ↓            │
│  Hopcroft最小化  │
│     ↓            │
│  最小DFA         │
│     ↓            │
│  代码生成        │
│     ↓            │
│  词法分析器.cpp  │
│                  │
└──────────────────┘
```
